{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80aa3101",
   "metadata": {},
   "source": [
    "# Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8d0936",
   "metadata": {},
   "source": [
    "## Fiction (with examples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "801bb5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b87ecba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2\n"
     ]
    }
   ],
   "source": [
    "# set directory to get .env file\n",
    "%cd \"/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16067e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gpt_formality_ratings</th>\n",
       "      <th>Text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>gpt_coding_raw</th>\n",
       "      <th>gpt_coding_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The Story of the Queen The Story of the Queen ...</td>\n",
       "      <td>637338-the-story-of-the-queen.txt</td>\n",
       "      <td>1903</td>\n",
       "      <td>11</td>\n",
       "      <td>Fiction.</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Burn Your Maps Burn Your Maps Robyn Joy Leff A...</td>\n",
       "      <td>302385-burn-your-maps.txt</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>fiction</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Neurotic S Notebook The Neurotic S Noteboo...</td>\n",
       "      <td>658882-the-neurotic-s-notebook.txt</td>\n",
       "      <td>1962</td>\n",
       "      <td>6</td>\n",
       "      <td>The text is fiction.</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Their Wedding Journey Their Wedding Journey Wi...</td>\n",
       "      <td>630459-their-wedding-journey.txt</td>\n",
       "      <td>1871</td>\n",
       "      <td>8</td>\n",
       "      <td>fiction.</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>De Grey : A Romance De Grey : A Romance IT was...</td>\n",
       "      <td>629196-de-grey-a-romance.txt</td>\n",
       "      <td>1868</td>\n",
       "      <td>7</td>\n",
       "      <td>fiction</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PS PS Jill McCorkle What I know now is that I ...</td>\n",
       "      <td>307540-ps.txt</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>fiction</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3768</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Once I Lived Once I Lived Karl Kirchwey A poem...</td>\n",
       "      <td>559160-once-i-lived.txt</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>The text is fiction.</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Shanghai Murmur Shanghai Murmur Te-Ping Chen A...</td>\n",
       "      <td>617269-shanghai-murmur.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>fiction</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Parents Parents Greg Delanty What do any of us...</td>\n",
       "      <td>308024-parents.txt</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>fiction</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Journal of a Plague Year Journal of a Plague Y...</td>\n",
       "      <td>664183-journal-of-a-plague-year.txt</td>\n",
       "      <td>1973</td>\n",
       "      <td>8</td>\n",
       "      <td>fiction</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  gpt_formality_ratings  \\\n",
       "0        2476                    1.0   \n",
       "1        6773                    0.0   \n",
       "2        6116                    0.0   \n",
       "3        3047                    1.0   \n",
       "4        4092                    1.0   \n",
       "5        3218                    0.0   \n",
       "6        3768                    1.0   \n",
       "7        3463                    0.0   \n",
       "8        3414                    0.0   \n",
       "9        1192                    0.0   \n",
       "\n",
       "                                                Text  \\\n",
       "0  The Story of the Queen The Story of the Queen ...   \n",
       "1  Burn Your Maps Burn Your Maps Robyn Joy Leff A...   \n",
       "2  The Neurotic S Notebook The Neurotic S Noteboo...   \n",
       "3  Their Wedding Journey Their Wedding Journey Wi...   \n",
       "4  De Grey : A Romance De Grey : A Romance IT was...   \n",
       "5  PS PS Jill McCorkle What I know now is that I ...   \n",
       "6  Once I Lived Once I Lived Karl Kirchwey A poem...   \n",
       "7  Shanghai Murmur Shanghai Murmur Te-Ping Chen A...   \n",
       "8  Parents Parents Greg Delanty What do any of us...   \n",
       "9  Journal of a Plague Year Journal of a Plague Y...   \n",
       "\n",
       "                             file_name  year  month        gpt_coding_raw  \\\n",
       "0    637338-the-story-of-the-queen.txt  1903     11              Fiction.   \n",
       "1            302385-burn-your-maps.txt  2002      1               fiction   \n",
       "2   658882-the-neurotic-s-notebook.txt  1962      6  The text is fiction.   \n",
       "3     630459-their-wedding-journey.txt  1871      8              fiction.   \n",
       "4         629196-de-grey-a-romance.txt  1868      7               fiction   \n",
       "5                        307540-ps.txt  2009      8               fiction   \n",
       "6              559160-once-i-lived.txt  2018      6  The text is fiction.   \n",
       "7           617269-shanghai-murmur.txt  2021      1               fiction   \n",
       "8                   308024-parents.txt  2010      5               fiction   \n",
       "9  664183-journal-of-a-plague-year.txt  1973      8               fiction   \n",
       "\n",
       "  gpt_coding_final  \n",
       "0          fiction  \n",
       "1          fiction  \n",
       "2          fiction  \n",
       "3          fiction  \n",
       "4          fiction  \n",
       "5          fiction  \n",
       "6          fiction  \n",
       "7          fiction  \n",
       "8          fiction  \n",
       "9          fiction  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/500-words-Atlantic-CSV-Formal-Informal-Fiction-Full.csv')\n",
    "df.head(10) #grab the text column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b8ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(df)\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dbb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fiction examples \n",
    "examples=pd.read_csv('/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/GPT-examples/Atlantic-Fiction-Examples.csv', index_col=0)\n",
    "examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8268145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df.Text.values #save the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd35b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first 5 text values\n",
    "print(inputs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef891bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load other dependencies \n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7645dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "title='Atlantic'\n",
    "subtitle='Fiction'\n",
    "stim_set=title+'-'+subtitle\n",
    "seed=1 #set seed to make sure we get reproducable results \n",
    "temperature=0.1 #want a low baking temp to have little variability or creativity \n",
    "engine='gpt-3.5-turbo' #change this to use different models\n",
    "n_context=1\n",
    "cache = True   \n",
    "resume=False\n",
    "# MIDI='freq' #or 'name', 'number', 'freq'\n",
    "audience='People'\n",
    "item='Text'\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#apiKey = os.environ.get('steven_key') #for stevens key \n",
    "\n",
    "apiKey = os.environ.get('angela_key') #for angelas key \n",
    "\n",
    "openai.api_key = apiKey \n",
    "\n",
    "if cache:\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996bcd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(current):#(example_idxs, current_pair):\n",
    "    prompt = f\"\"\"Your task is to classify a piece of as either formal or informal. \n",
    "You will be provided with two examples of formal text and two examples of informal text. Answer only with a number: 1 if formal, and 0 if informal.  \n",
    "\n",
    "Text: {examples.Example.iloc[0]} \n",
    "Rating: {examples.Label.iloc[0]}\n",
    "    \n",
    "Text: {examples.Example.iloc[1]}\n",
    "Rating: {examples.Label.iloc[1]}\n",
    "\n",
    "Text: {examples.Example.iloc[2]}\n",
    "Rating: {examples.Label.iloc[2]}\n",
    "\n",
    "Text: {examples.Example.iloc[3]}\n",
    "Rating: {examples.Label.iloc[3]}\n",
    "    \n",
    "Text: {inputs[current]}\n",
    "Rating:\n",
    "\"\"\"\n",
    "    if n_context==0:\n",
    "        prompt = f\"\"\"Is the following piece of text formal or informal? Answer only with a number: 1 if formal, and 0 if informal Here is the text:\\n{inputs[current]}\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "cache_folder = f'cache/{stim_set}'\n",
    "os.makedirs(cache_folder, exist_ok=True)\n",
    "def create_cache_filename():\n",
    "    filename = f'{stim_set}-{n_context}-{engine}-{temperature}-{seed}'\n",
    "    # if args.shuffle_context_each_draw:\n",
    "    #     filename += '-shuffle'\n",
    "    return os.path.join(cache_folder, filename + '.json')\n",
    "\n",
    "if not resume:\n",
    "    visited = []\n",
    "    predicted_ratings = np.zeros((len(inputs)))\n",
    "    request_count = 0\n",
    "\n",
    "cache = {}\n",
    "\n",
    "if cache and os.path.exists(create_cache_filename()):\n",
    "    cache = json.load(open(create_cache_filename()))\n",
    "cached_keys = list(cache.keys())\n",
    "\n",
    "for idx1, bname1 in enumerate(tqdm(inputs)):\n",
    "    current = idx1\n",
    "    if current in visited and predicted_ratings[current]!=0:\n",
    "        print(f'Already visited {current}')\n",
    "        continue\n",
    "\n",
    "    visited.append(current)\n",
    "\n",
    "    key = f'{current}'\n",
    "    if key in cached_keys:\n",
    "        choices = cache[key]['choices']\n",
    "        print('Using cached choices for key', key)\n",
    "    else:\n",
    "        prompt = generate_prompt(current)#(example_idxs, current_pair)\n",
    "        response=False\n",
    "        i=0\n",
    "        while not response:\n",
    "            i+=1\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=engine,\n",
    "                    messages=[{'role':'user', 'content':prompt}],\n",
    "                    temperature=temperature,\n",
    "                    timeout=10\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f'Attempt {i} failed')\n",
    "                time.sleep(5)\n",
    "        choices = [dict(choice.items()) for choice in response.choices]\n",
    "\n",
    "        cache[key] = {\n",
    "            'prompt': prompt,\n",
    "            'choices': choices,\n",
    "            'created': response.created\n",
    "        }\n",
    "\n",
    "        request_count += 1\n",
    "        if cache and request_count % 5 == 0:\n",
    "            json.dump(cache, open(create_cache_filename(), 'w'))\n",
    "\n",
    "    try:\n",
    "        answer = choices[0]['message']['content'].replace('\\n', '').strip()\n",
    "        predicted_ratings[idx1] = int(answer)\n",
    "    except:\n",
    "        print('Error', cache[key])\n",
    "\n",
    "os.makedirs(f'predictions/{stim_set}', exist_ok=True)\n",
    "np.save(f'predictions/{stim_set}/{stim_set}-{n_context}-{engine}-{temperature}-{seed}.npy', predicted_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/600-words-Atlantic-CSV-Formal-Informal-Fiction-Full.csv\")\n",
    "# df_gpt4 = np.zeros((predicted_ratings.size, 3))\n",
    "# df_gpt4[np.arange(predicted_ratings.size), predicted_ratings.astype(int)] = 1\n",
    "predicted_ratings=np.load(f'predictions/{stim_set}/{stim_set}-{n_context}-{engine}-{temperature}-{seed}.npy', allow_pickle=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc227656",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings # just to check it ran smoothly\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f277f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_df_gpt35_250=pd.DataFrame(predicted_ratings, columns=['gpt_formality_ratings'])\n",
    "fiction_df_gpt35_250['Text']=df.Text.values\n",
    "fiction_df_gpt35_250['file_name']=df.file_name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2397e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the work\n",
    "output_directory = '/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/output/final/'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "fiction_df_gpt35_250.to_csv(os.path.join(output_directory, f'{stim_set}-{n_context}-{engine}-{temperature}-{seed}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd513e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### need to work on this \n",
    "\n",
    "# emotions=np.array(['yes','no'])\n",
    "df=df.reset_index()\n",
    "# one_hot = pd.get_dummies(df['human'])\n",
    "df=df.rename(columns={'human':'overall_inter_rater_reliability'})\n",
    "# df=df.join(one_hot)\n",
    "matches=np.all(df_gpt4[['offensive']]==df.reset_index(drop=True)[['offensive']],axis=1)\n",
    "np.mean(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85b19c0",
   "metadata": {},
   "source": [
    "## Non-fiction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c073fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd\n",
    "    # set directory to get .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05ade05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2\n"
     ]
    }
   ],
   "source": [
    "%cd \"/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68b2efe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_name</th>\n",
       "      <th>Text</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>gpt_coding_raw</th>\n",
       "      <th>gpt_coding_final</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35071</td>\n",
       "      <td>641130-the-wealth-we-wasted.txt</td>\n",
       "      <td>The Wealth We Wasted The Wealth We Wasted A. W...</td>\n",
       "      <td>1952</td>\n",
       "      <td>8</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>['The', 'Wealth', 'We', 'Wasted', 'The', 'Weal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35072</td>\n",
       "      <td>641803-the-peripatetic-reviewer.txt</td>\n",
       "      <td>The Peripatetic Reviewer The Peripatetic Revie...</td>\n",
       "      <td>1952</td>\n",
       "      <td>8</td>\n",
       "      <td>Non-fiction.</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>['The', 'Peripatetic', 'Reviewer', 'The', 'Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35073</td>\n",
       "      <td>641018-a-life-of-disagreement.txt</td>\n",
       "      <td>A Life of Disagreement A Life of Disagreement ...</td>\n",
       "      <td>1952</td>\n",
       "      <td>8</td>\n",
       "      <td>Non-fiction.</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>['A', 'Life', 'of', 'Disagreement', 'A', 'Life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35075</td>\n",
       "      <td>641902-spain.txt</td>\n",
       "      <td>Spain Spain on the World TodayDURING the riots...</td>\n",
       "      <td>1952</td>\n",
       "      <td>8</td>\n",
       "      <td>Non-fiction.</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>['Spain', 'Spain', 'on', 'the', 'World', 'Toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35076</td>\n",
       "      <td>642759-record-reviews.txt</td>\n",
       "      <td>Record Reviews Record Reviews John M. Conly by...</td>\n",
       "      <td>1952</td>\n",
       "      <td>8</td>\n",
       "      <td>Non-fiction.</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>['Record', 'Reviews', 'Record', 'Reviews', 'Jo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            file_name   \n",
       "0       35071      641130-the-wealth-we-wasted.txt  \\\n",
       "1       35072  641803-the-peripatetic-reviewer.txt   \n",
       "2       35073    641018-a-life-of-disagreement.txt   \n",
       "3       35075                     641902-spain.txt   \n",
       "4       35076            642759-record-reviews.txt   \n",
       "\n",
       "                                                Text  year  month   \n",
       "0  The Wealth We Wasted The Wealth We Wasted A. W...  1952      8  \\\n",
       "1  The Peripatetic Reviewer The Peripatetic Revie...  1952      8   \n",
       "2  A Life of Disagreement A Life of Disagreement ...  1952      8   \n",
       "3  Spain Spain on the World TodayDURING the riots...  1952      8   \n",
       "4  Record Reviews Record Reviews John M. Conly by...  1952      8   \n",
       "\n",
       "  gpt_coding_raw gpt_coding_final   \n",
       "0    non-fiction      non-fiction  \\\n",
       "1   Non-fiction.      non-fiction   \n",
       "2   Non-fiction.      non-fiction   \n",
       "3   Non-fiction.      non-fiction   \n",
       "4   Non-fiction.      non-fiction   \n",
       "\n",
       "                                              Tokens  \n",
       "0  ['The', 'Wealth', 'We', 'Wasted', 'The', 'Weal...  \n",
       "1  ['The', 'Peripatetic', 'Reviewer', 'The', 'Per...  \n",
       "2  ['A', 'Life', 'of', 'Disagreement', 'A', 'Life...  \n",
       "3  ['Spain', 'Spain', 'on', 'the', 'World', 'Toda...  \n",
       "4  ['Record', 'Reviews', 'Record', 'Reviews', 'Jo...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the 5 separate dataframes\n",
    "\n",
    "#1 - done\n",
    "#df=pd.read_csv('/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/500-words-Atlantic-CSV-Formal-Informal-NonFiction-Full_1.csv')\n",
    "\n",
    "\n",
    "#2 -done\n",
    "#df=pd.read_csv('/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/500-words-Atlantic-CSV-Formal-Informal-NonFiction-Full_2.csv')\n",
    "\n",
    "#3 - done\n",
    "#df=pd.read_csv('/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/500-words-Atlantic-CSV-Formal-Informal-NonFiction-Full_3.csv')\n",
    "\n",
    "#4 - done\n",
    "#df=pd.read_csv('/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/500-words-Atlantic-CSV-Formal-Informal-NonFiction-Full_4.csv')\n",
    "\n",
    "#5 - done\n",
    "df=pd.read_csv('/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/500-words-Atlantic-CSV-Formal-Informal-NonFiction-Full_5.csv')\n",
    "\n",
    "\n",
    "df.head() #grab the text column \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7245e603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 7342\n"
     ]
    }
   ],
   "source": [
    "num_rows = df.shape[0]\n",
    "\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8adbe28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "# Specify the maximum token count threshold\n",
    "max_token_count = 3000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2d4320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 7342\n"
     ]
    }
   ],
   "source": [
    "#dealing with too many tokens NEED TO RUN TO REMOVE SHITTY DATA\n",
    "\n",
    "# Define a function to count tokens in a text\n",
    "def count_tokens(text):\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "# Apply token count function to 'Text' column and filter based on maximum token count\n",
    "df = df[df['Text'].apply(count_tokens) <= max_token_count]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "num_rows = df.shape[0]\n",
    "\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbe650e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>year</th>\n",
       "      <th>Example</th>\n",
       "      <th>Label</th>\n",
       "      <th>formality_rating</th>\n",
       "      <th>gpt_coding_final</th>\n",
       "      <th>angela_formality_rating</th>\n",
       "      <th>lyle_formality_rating</th>\n",
       "      <th>ben_formality_rating</th>\n",
       "      <th>steven_formality_rating</th>\n",
       "      <th>interrater_reliability</th>\n",
       "      <th>overall_inter_rater_reliability</th>\n",
       "      <th>GPT3_5_NO_example</th>\n",
       "      <th>no_example_cor</th>\n",
       "      <th>GPT3_5_with_example</th>\n",
       "      <th>example_cor</th>\n",
       "      <th>GPT3_5_2_example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628188-the-question-of-the-hour.txt</td>\n",
       "      <td>1861</td>\n",
       "      <td>However true this may be in the main, — and it...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280369</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633747-why-our-science-students-go-to-germany.txt</td>\n",
       "      <td>1889</td>\n",
       "      <td>Doubtless each individual is influenced by a v...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280369</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>659289-why-im-a-cop-interviews-from-a-reporter...</td>\n",
       "      <td>1969</td>\n",
       "      <td>New York policeman for ten years; recently bec...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280369</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>307617-how-american-health-care-killed-my-fath...</td>\n",
       "      <td>2009</td>\n",
       "      <td>Like every grieving family member, I looked fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.222222</td>\n",
       "      <td>0.280369</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  year   \n",
       "0                628188-the-question-of-the-hour.txt  1861  \\\n",
       "1  633747-why-our-science-students-go-to-germany.txt  1889   \n",
       "2  659289-why-im-a-cop-interviews-from-a-reporter...  1969   \n",
       "3  307617-how-american-health-care-killed-my-fath...  2009   \n",
       "\n",
       "                                             Example  Label  formality_rating   \n",
       "0  However true this may be in the main, — and it...      1               NaN  \\\n",
       "1  Doubtless each individual is influenced by a v...      1               NaN   \n",
       "2  New York policeman for ten years; recently bec...      0               NaN   \n",
       "3  Like every grieving family member, I looked fo...      0               NaN   \n",
       "\n",
       "  gpt_coding_final  angela_formality_rating  lyle_formality_rating   \n",
       "0      non-fiction                        1                      1  \\\n",
       "1      non-fiction                        1                      1   \n",
       "2      non-fiction                        0                      0   \n",
       "3      non-fiction                        1                      0   \n",
       "\n",
       "   ben_formality_rating  steven_formality_rating  interrater_reliability   \n",
       "0                     1                        1                1.000000  \\\n",
       "1                     1                        1                1.000000   \n",
       "2                     0                        0                1.000000   \n",
       "3                     0                        0               -0.222222   \n",
       "\n",
       "   overall_inter_rater_reliability  GPT3_5_NO_example  no_example_cor   \n",
       "0                         0.280369                  1             NaN  \\\n",
       "1                         0.280369                  1             NaN   \n",
       "2                         0.280369                  0             NaN   \n",
       "3                         0.280369                  0             NaN   \n",
       "\n",
       "   GPT3_5_with_example  example_cor  GPT3_5_2_example  \n",
       "0                    1          NaN                 1  \n",
       "1                    1          NaN                 1  \n",
       "2                    0          NaN                 0  \n",
       "3                    0          NaN                 0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fiction examples \n",
    "examples=pd.read_csv('/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/GPT-examples/Atlantic-Nonfiction-Examples.csv')\n",
    "examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e2d5493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The Wealth We Wasted The Wealth We Wasted A. W. Smith A. W. SMITH , who was born in Spain of British parents , lived in Russia as a boy and was educated at Shrewsbury and at Sandhurst . He served with the British Army throughout both World Wars . For some years he has made his home in Ipswich , Massachusetts , where he wrote his books , The Captain Departed and The Sword and the Rose , and a number of short stories which have appeared in the Atlantic . He has recently become an American citizen , and is today a Vice President on the staff of The Conservation Foundation . by A. W. SMITH1IT is probably near-heresy to suggest that the pioneer forefathers may not have been well equipped to deal intelligently with the problems posed in their new environment . Many of their practices , so evil and so wasteful in the coldly superior light of the middle of the twentieth century , may have been forced on them by the demands of the moment . But these are not sufficient to account for the destructive waste which has been the habit of American pioneers up to our own times.The early settlers — and the majority of later ones , too — were English . They came to a land which differed but little from England in climate and soil types . It had much the same pattern of precipitation . Winter might be a bit colder , summer rather hotter , but the same crops could be grown with much the same techniques . Yet the first settlers and their successors failed to bring with them any significant part of the great available knowledge of land use . They seem to have abandoned past experience almost before they started , together with any feel for land or sympathy for its needs.These people came from a land of highly developed resource use , where the countryside was loved and appreciated for itself . It was the England of Tom Tusser , the farmer poet , who coined such pleasant and even truthful aphorisms as `` March dust worth a ransom of gold '' ; `` Sweet April showers spring May flowers '' ; `` Calm in June sets corn in tune . '' It was the England of Evelyn , of Izaak Walton and Cotton . And of the anonymous author who improved on Bernard of Cluny 's Jerusalem the Golden with a lovelier and longer version which includes what is clearly a trout stream among the important delights of the life to come.Whether they came from motives of freedom or fortune , the early settlers seem to have been taken completely by surprise by what they found in America . The Jamestown Settlement , consisting of forty-eight gentlemen and four carpenters , were told quite plainly at the outset that they would be `` banished men '' unless they produced cargoes to the value\"\n",
      " \"The Peripatetic Reviewer The Peripatetic Reviewer Edward Weeks BECAUSE I find fishing , the play of sunlight and shadow on water and the signals of the life beneath , the most complete and bewitching relaxation from a life devoted to print , I am occasionally asked for advice , not as an expert but as an addict who has learned from his trials . `` Jack has always had a yen to fish , '' said the wife of a friend recently , `` but now that he 's got the time , he 's too shy to begin . Claims he does n't know anything about casting or what tackle to get . How do I push him in ? '' I think that 's true of more fifty-year-olds than ever admit it : their friends who belong to the fraternity of the dry fly talk a jargon that will scare away most beginners . What Jack needs for his conversion is the joy of catching fish ; the art of not catching he can develop later . Specifically what he needs is an old hat , a pair of sneakers , and a bottle of insect repellent . I did my learning on a Bristol split-bamboo rod that cost $ 16 ; Jack can do his on a mediumpriced fly rod and reel at a cost of $ 30 , or as much more as he cares to pay ( the famous name-rods , a Leonard , a Thomas , a Paine , or a Hardy , will come close to $ 100 ) . But most of all , Jack needs the tight line and the feel of a jumping smallmouthed or the swift rush of a trout . He should not be ashamed to use bait . I know two friends who fish a mountain brook . The brook has two branches winding through three miles of thick brush . They leave one car at the bottom , drive to the top , and go their separate ways with worm cans . They never fail to catch enough brookies for the meal when they converge — and incidentally , the bottom pool is an excellent icebox for their bottled beer . So what Jack needs is worms for the trout brook , or minnows or hellgrammites for the bass pond . Plenty of time for the dry flies after his conversion . A second friend , setting off in early July for a month 's cruise which will carry him as far as Newfoundland , asked if I thought he could hold a salmon on his telescopic steel rod . I said I thought he could , and gave him the names of the three standard wet flies ( size 4 ) which a salmon might rise to at the river 's mouth —Black Dose , Durham Ranger , and Mar Lodge . That collapsible steel rod of his is probably the best all-purpose implement for\"\n",
      " \"A Life of Disagreement A Life of Disagreement Romney Wheeler Of all the television programs in recent months , few attracted such widespread praise as the half-hour conversation by BERTRAND RUSSELL with Romney Wheeler , filmed in London by the National Broadcasting Company and shown over the NBC network and BBC-TV on the occasion of Earl Russell 's eightieth birthday . Author , philosopher , mathematician , and recipient of the Nobel Prize in Literature , Earl Russell believes that mankind will yet `` emerge into some world that will be happier than any world that has existed in the past . '' We feel sure Atlantic readers trill enjoy this complete transcript of the interview . An Interview with Bertrand RussellWHEELER . — Lord Russell , as you celebrate your eightieth birthday , we 'd like you to tell us what you think you have learned and what you think you will never learn in your career as a philosopher.RUSSELL . — Well , there are some things that I do n't think I shall ever learn and indeed I hope I shall never learn . I do n't wish to learn to change my hopes for the world . I am prepared to change my beliefs about the state of the world , but not my hopes . About that I wish to remain constant . I think we might call the subject of our talk `` Eighty years of changing beliefs and unchanging hopes . `` It 's very difficult for anybody born since 1914 to realize how profoundly different the world is now from what it was when I was a child . The change has been almost unbelievable . I try as best I can , despite my years , to get used to living in a world of atom bombs ; a world where ancient empires vanish like morning mist , where we have to accustom ourselves to Asiatic self-assertion , the Communist menace . The world is altogether different from what it was when I was young . It 's an extraordinarily difficult thing for an old man to live in such a world . I was born in 1872 . My parents died when I was still an infant . And so I was brought up by my grandparents.WHEELER . — Can you tell us something about your grandfather ? RUSSELL . — Yes . He was born in the early years of the French Revolution . He was a member of Parliament while Napoleon was on the throne . In common with Fox , he thought English hostility to Napoleon was excessive , and he visited Napoleon in Elba . It was he who introduced the reform in 1832 which started England on the road towards democracy . He was Prime Minister during the Mexican War , during the Revolutions of 1848 . I remember him quite well . But as you can see , he belonged to an age that\"]\n"
     ]
    }
   ],
   "source": [
    "inputs = df.Text.values #save the text\n",
    "print(inputs[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b35e7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load other dependencies \n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b414459",
   "metadata": {},
   "outputs": [],
   "source": [
    "title='Atlantic'\n",
    "subtitle='Non-fiction'\n",
    "stim_set=title+'-'+subtitle\n",
    "seed=1\n",
    "temperature=0.1 #want a low baking temp to have little variability or creativity \n",
    "engine='gpt-3.5-turbo' #change this to use different models\n",
    "n_context=1\n",
    "cache = True   \n",
    "resume=False\n",
    "# MIDI='freq' #or 'name', 'number', 'freq'\n",
    "audience='People'\n",
    "item='Text'\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "apiKey = os.environ.get('angela_key') #for angelas key \n",
    "\n",
    "openai.api_key = apiKey \n",
    "\n",
    "if cache:\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "239a74e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c590ab3d4b1f487a91f2a5d411753465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7342 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed\n",
      "Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 14:25:17 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df70c49be3c43f9-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88684 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89119 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88650 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88852 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89089 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89164 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88628 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88706 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 15:03:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df744254c6f433d-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 15:19:27 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df75ba8894d41cd-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 15:24:55 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df763ab1bac41cd-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89102 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88600 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89105 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88569 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88675 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88839 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88469 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88470 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88415 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88895 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88831 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88749 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88904 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 15:39:52 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df779880aae41cd-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88627 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88895 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88770 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89015 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88786 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88997 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88739 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89203 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88454 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 15:58:08 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df7945178e60f4d-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 16:25:06 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df7bbd23fc60f4d-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 16:34:59 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df7ca4a1c670f4d-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89440 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88450 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89392 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88924 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89430 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89231 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88978 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89307 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89298 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89379 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89296 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88956 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88925 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88548 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88428 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88696 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88520 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88448 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88618 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88414 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88527 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89226 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89389 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89163 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89060 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 17:18:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df80a228f04c330-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 17:37:09 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df825799941c330-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600)\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 17:57:58 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df843de78d4c468-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88749 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88541 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89395 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89031 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89259 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88657 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 18:11:52 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df858378b78c468-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 18:20:07 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df8644b980ec468-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 18:25:45 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df86c88b8fdc468-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88777 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88489 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88832 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88749 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88719 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89018 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89135 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88846 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 2 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 18:34:49 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df879d65a50c468-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89084 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 18:42:00 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df8845e9c6ac468-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 18:48:59 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df88e9409071927-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 18:57:58 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df89bbfda0d1927-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 19:04:37 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df8a57cf9571927-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 19:28:39 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df8c8ae4aad1927-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 19:34:05 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df8d0a96fd51927-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88880 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 2 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88867 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89190 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 89095 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Rate limit reached for default-gpt-3.5-turbo in organization org-D9XDwg2Sw2y54gEdPpW9Mqvj on tokens per min. Limit: 90000 / min. Current: 88876 / min. Contact us through our help center at help.openai.com if you continue to have issues.\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 19:44:03 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df8df4248ac0f65-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n",
      "Attempt 1 failed\n",
      "Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Fri, 30 Jun 2023 19:57:27 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7df8f2dd48680f65-EWR', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "\n",
      "Attempt 1 failed\n",
      "The server is overloaded or not ready yet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_prompt(current):#(example_idxs, current_pair):\n",
    "    prompt = f\"\"\"Your task is to classify a piece of as either formal or informal. \n",
    "You will be provided with two examples of formal text and two examples of informal text. Answer only with a number: 1 if formal, and 0 if informal.  \n",
    "\n",
    "Text: {examples.Example.iloc[0]} \n",
    "Rating: {examples.Label.iloc[0]}\n",
    "    \n",
    "Text: {examples.Example.iloc[1]}\n",
    "Rating: {examples.Label.iloc[1]}\n",
    "\n",
    "Text: {examples.Example.iloc[2]}\n",
    "Rating: {examples.Label.iloc[2]}\n",
    "\n",
    "Text: {examples.Example.iloc[3]}\n",
    "Rating: {examples.Label.iloc[3]}\n",
    "    \n",
    "Text: {inputs[current]}\n",
    "Rating:\n",
    "\"\"\"\n",
    "    if n_context==0:\n",
    "        prompt = f\"\"\"Is the following piece of text formal or informal? Answer only with a number: 1 if formal, and 0 if informal Here is the text:\\n{inputs[current]}\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "cache_folder = f'cache/{stim_set}'\n",
    "os.makedirs(cache_folder, exist_ok=True)\n",
    "\n",
    "def create_cache_filename():\n",
    "    filename = f'{stim_set}-{n_context}-{engine}-{temperature}-{seed}'\n",
    "    # if args.shuffle_context_each_draw:\n",
    "    #     filename += '-shuffle'\n",
    "    return os.path.join(cache_folder, filename + '.json')\n",
    "\n",
    "if not resume:\n",
    "    visited = []\n",
    "    predicted_ratings = np.zeros((len(inputs)))\n",
    "    request_count = 0\n",
    "\n",
    "cache = {}\n",
    "\n",
    "if cache and os.path.exists(create_cache_filename()):\n",
    "    cache = json.load(open(create_cache_filename()))\n",
    "cached_keys = list(cache.keys())\n",
    "\n",
    "for idx1, bname1 in enumerate(tqdm(inputs)):\n",
    "    current = idx1\n",
    "    if current in visited and predicted_ratings[current] != 0:\n",
    "        print(f'Already visited {current}')\n",
    "        continue\n",
    "\n",
    "    visited.append(current)\n",
    "\n",
    "    key = f'{current}'\n",
    "    if key in cached_keys:\n",
    "        choices = cache[key]['choices']\n",
    "        print('Using cached choices for key', key)\n",
    "    else:\n",
    "        prompt = generate_prompt(current)\n",
    "        response = False\n",
    "        i = 0\n",
    "        while not response:\n",
    "            i += 1\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=engine,\n",
    "                    messages=[{'role': 'user', 'content': prompt}],\n",
    "                    temperature=temperature,\n",
    "                    timeout=10\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f'Attempt {i} failed\\n{e}\\n')\n",
    "                \n",
    "                time.sleep(7) #7 second delay \n",
    "        choices = [dict(choice.items()) for choice in response.choices]\n",
    "\n",
    "        cache[key] = {\n",
    "            'prompt': prompt,\n",
    "            'choices': choices,\n",
    "            'created': response.created\n",
    "        }\n",
    "\n",
    "        request_count += 1\n",
    "        if cache and request_count % 5 == 0:\n",
    "            json.dump(cache, open(create_cache_filename(), 'w'))\n",
    "\n",
    "    try:\n",
    "        answer = choices[0]['message']['content'].replace('\\n', '').strip()\n",
    "        predicted_ratings[idx1] = int(answer)\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}\\n\\n{cache[key]}')\n",
    "\n",
    "os.makedirs(f'predictions/{stim_set}', exist_ok=True)\n",
    "np.save(f'predictions/{stim_set}/{stim_set}-{n_context}-{engine}-{temperature}-{seed}.npy', predicted_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d581d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the 5 separate dataframes\n",
    "\n",
    "#1 - done\n",
    "#df=pd.read_csv('/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/500-words-Atlantic-CSV-Formal-Informal-NonFiction-Full_1.csv')\n",
    "\n",
    "\n",
    "#2 - done\n",
    "#df=pd.read_csv('/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/500-words-Atlantic-CSV-Formal-Informal-NonFiction-Full_2.csv')\n",
    "\n",
    "#3\n",
    "#df=pd.read_csv('/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/500-words-Atlantic-CSV-Formal-Informal-NonFiction-Full_3.csv')\n",
    "\n",
    "#4\n",
    "#df=pd.read_csv('/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/500-words-Atlantic-CSV-Formal-Informal-NonFiction-Full_4.csv')\n",
    "\n",
    "#5\n",
    "#df=pd.read_csv('/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/500-words-Atlantic-CSV-Formal-Informal-NonFiction-Full_5.csv')\n",
    "\n",
    "\n",
    "df.head() #grab the text column # df_gpt4 = np.zeros((predicted_ratings.size, 3))\n",
    "# df_gpt4[np.arange(predicted_ratings.size), predicted_ratings.astype(int)] = 1\n",
    "predicted_ratings=np.load(f'predictions/{stim_set}/{stim_set}-{n_context}-{engine}-{temperature}-{seed}.npy', allow_pickle=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c14e677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 7342\n"
     ]
    }
   ],
   "source": [
    "#dealing with too many tokens NEED TO RUN TO REMOVE SHITTY DATA\n",
    "\n",
    "# Define a function to count tokens in a text\n",
    "def count_tokens(text):\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "# Apply token count function to 'Text' column and filter based on maximum token count\n",
    "df = df[df['Text'].apply(count_tokens) <= max_token_count]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "num_rows = df.shape[0]\n",
    "\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85be58ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'file_name', 'Text', 'year', 'month', 'gpt_coding_raw',\n",
       "       'gpt_coding_final', 'Tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings # just to check it ran smoothly\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35cf6fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonfiction_df_gpt35=pd.DataFrame(predicted_ratings, columns=['formality_ratings'])\n",
    "nonfiction_df_gpt35['Text']=df.Text.values\n",
    "nonfiction_df_gpt35['file_name']=df.file_name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5207df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the work\n",
    "output_directory = '/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/output/final'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "nonfiction_df_gpt35.to_csv(os.path.join(output_directory, f'{stim_set}-{n_context}-{engine}-{temperature}-{seed}.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
