{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80aa3101",
   "metadata": {},
   "source": [
    "# GPT-3.5 Classifier "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca8d0936",
   "metadata": {},
   "source": [
    "## Arousal (with examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "801bb5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b87ecba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2\n"
     ]
    }
   ],
   "source": [
    "# set directory to get .env file. You will need to change this to wherever your API key (.env file) is, as well as where you want to save your results\n",
    "%cd \"/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16067e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gpt_formality_ratings</th>\n",
       "      <th>Text</th>\n",
       "      <th>file_name</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>gpt_coding_raw</th>\n",
       "      <th>gpt_coding_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The Story of the Queen The Story of the Queen ...</td>\n",
       "      <td>637338-the-story-of-the-queen.txt</td>\n",
       "      <td>1903</td>\n",
       "      <td>11</td>\n",
       "      <td>Fiction.</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Burn Your Maps Burn Your Maps Robyn Joy Leff A...</td>\n",
       "      <td>302385-burn-your-maps.txt</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>fiction</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Neurotic S Notebook The Neurotic S Noteboo...</td>\n",
       "      <td>658882-the-neurotic-s-notebook.txt</td>\n",
       "      <td>1962</td>\n",
       "      <td>6</td>\n",
       "      <td>The text is fiction.</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Their Wedding Journey Their Wedding Journey Wi...</td>\n",
       "      <td>630459-their-wedding-journey.txt</td>\n",
       "      <td>1871</td>\n",
       "      <td>8</td>\n",
       "      <td>fiction.</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>De Grey : A Romance De Grey : A Romance IT was...</td>\n",
       "      <td>629196-de-grey-a-romance.txt</td>\n",
       "      <td>1868</td>\n",
       "      <td>7</td>\n",
       "      <td>fiction</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PS PS Jill McCorkle What I know now is that I ...</td>\n",
       "      <td>307540-ps.txt</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "      <td>fiction</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3768</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Once I Lived Once I Lived Karl Kirchwey A poem...</td>\n",
       "      <td>559160-once-i-lived.txt</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>The text is fiction.</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Shanghai Murmur Shanghai Murmur Te-Ping Chen A...</td>\n",
       "      <td>617269-shanghai-murmur.txt</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>fiction</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Parents Parents Greg Delanty What do any of us...</td>\n",
       "      <td>308024-parents.txt</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>fiction</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Journal of a Plague Year Journal of a Plague Y...</td>\n",
       "      <td>664183-journal-of-a-plague-year.txt</td>\n",
       "      <td>1973</td>\n",
       "      <td>8</td>\n",
       "      <td>fiction</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  gpt_formality_ratings  \\\n",
       "0        2476                    1.0   \n",
       "1        6773                    0.0   \n",
       "2        6116                    0.0   \n",
       "3        3047                    1.0   \n",
       "4        4092                    1.0   \n",
       "5        3218                    0.0   \n",
       "6        3768                    1.0   \n",
       "7        3463                    0.0   \n",
       "8        3414                    0.0   \n",
       "9        1192                    0.0   \n",
       "\n",
       "                                                Text  \\\n",
       "0  The Story of the Queen The Story of the Queen ...   \n",
       "1  Burn Your Maps Burn Your Maps Robyn Joy Leff A...   \n",
       "2  The Neurotic S Notebook The Neurotic S Noteboo...   \n",
       "3  Their Wedding Journey Their Wedding Journey Wi...   \n",
       "4  De Grey : A Romance De Grey : A Romance IT was...   \n",
       "5  PS PS Jill McCorkle What I know now is that I ...   \n",
       "6  Once I Lived Once I Lived Karl Kirchwey A poem...   \n",
       "7  Shanghai Murmur Shanghai Murmur Te-Ping Chen A...   \n",
       "8  Parents Parents Greg Delanty What do any of us...   \n",
       "9  Journal of a Plague Year Journal of a Plague Y...   \n",
       "\n",
       "                             file_name  year  month        gpt_coding_raw  \\\n",
       "0    637338-the-story-of-the-queen.txt  1903     11              Fiction.   \n",
       "1            302385-burn-your-maps.txt  2002      1               fiction   \n",
       "2   658882-the-neurotic-s-notebook.txt  1962      6  The text is fiction.   \n",
       "3     630459-their-wedding-journey.txt  1871      8              fiction.   \n",
       "4         629196-de-grey-a-romance.txt  1868      7               fiction   \n",
       "5                        307540-ps.txt  2009      8               fiction   \n",
       "6              559160-once-i-lived.txt  2018      6  The text is fiction.   \n",
       "7           617269-shanghai-murmur.txt  2021      1               fiction   \n",
       "8                   308024-parents.txt  2010      5               fiction   \n",
       "9  664183-journal-of-a-plague-year.txt  1973      8               fiction   \n",
       "\n",
       "  gpt_coding_final  \n",
       "0          fiction  \n",
       "1          fiction  \n",
       "2          fiction  \n",
       "3          fiction  \n",
       "4          fiction  \n",
       "5          fiction  \n",
       "6          fiction  \n",
       "7          fiction  \n",
       "8          fiction  \n",
       "9          fiction  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/500-words-Atlantic-CSV-Formal-Informal-Fiction-Full.csv') # load in the data using pandas and take a peek at the first 10 rows\n",
    "df.head(10) #grab the text column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dbb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in your examples as `examples` and take a peek at the dataframe\n",
    "examples=pd.read_csv('/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/GPT-examples/Atlantic-Fiction-Examples.csv', index_col=0)\n",
    "examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8268145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df.Text.values #save the text as an object called inputs. we'll use this to run our observations through the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd35b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first 5 text values to check everything out \n",
    "print(inputs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef891bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load other dependencies \n",
    "import argparse \n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7645dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "title='BBPRIME'\n",
    "subtitle='Arousal'\n",
    "stim_set=title+'-'+subtitle\n",
    "seed=1 #set seed to make sure we get reproducable results \n",
    "temperature=0.0 #want a low baking temp to have little variability or creativity, and so we can get the same results every. single. time. range is 0-1\n",
    "engine='gpt-3.5-turbo' #change this to use different models available to you via OpenAI\n",
    "n_context=1\n",
    "cache = True   \n",
    "resume=False\n",
    "# MIDI='freq' #or 'name', 'number', 'freq'\n",
    "audience='People'\n",
    "item='Text'\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "apiKey = os.environ.get('steven_key') #for stevens key. update to you whatever you're calling your api_key. it should look like this in your file\n",
    "\n",
    "# apiKey = sk-ZJ...................4T\n",
    "\n",
    "openai.api_key = apiKey #installize the key so we can access\n",
    "\n",
    "if cache:\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996bcd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(current):#(example_idxs, current_pair):\n",
    "    prompt = f\"\"\"Your task is to classify a piece of as having either high or low arousal. Arousal is the extent to which a stimulus is calming or exciting. Examples of emotions with high\n",
    "arousal are anger, joy, fear, surprise, or anxiety. Examples of emotions with low arousal are sadness, relaxation, disgust, content, or peace.\n",
    "\n",
    "You will be provided with X examples of high arousal text and X examples of low text. Answer with only a whole number betwen 1 and 5, with 1 being\n",
    " low arousal and 5 being high arousal.\n",
    "\n",
    "\n",
    "Text: {examples.Example.iloc[0]}  \n",
    "Rating: {examples.Label.iloc[0]}\n",
    "    \n",
    "Text: {examples.Example.iloc[1]}\n",
    "Rating: {examples.Label.iloc[1]}\n",
    "\n",
    "Text: {examples.Example.iloc[2]}\n",
    "Rating: {examples.Label.iloc[2]}\n",
    "\n",
    "Text: {examples.Example.iloc[3]}\n",
    "Rating: {examples.Label.iloc[3]}\n",
    "    \n",
    "Text: {inputs[current]}\n",
    "Rating:\n",
    "\"\"\"\n",
    "    if n_context==0:\n",
    "        prompt = f\"\"\"What is the arousal of following piece of text? Answer only with a number between 1 and 5: 1 if low arousal, and 5 if high arousal Here is the text:\\n{inputs[current]}\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "cache_folder = f'cache/{stim_set}'\n",
    "os.makedirs(cache_folder, exist_ok=True)\n",
    "def create_cache_filename():\n",
    "    filename = f'{stim_set}-{n_context}-{engine}-{temperature}-{seed}'\n",
    "    # if args.shuffle_context_each_draw:\n",
    "    #     filename += '-shuffle'\n",
    "    return os.path.join(cache_folder, filename + '.json')\n",
    "\n",
    "if not resume:\n",
    "    visited = []\n",
    "    predicted_ratings = np.zeros((len(inputs)))\n",
    "    request_count = 0\n",
    "\n",
    "cache = {}\n",
    "\n",
    "if cache and os.path.exists(create_cache_filename()):\n",
    "    cache = json.load(open(create_cache_filename()))\n",
    "cached_keys = list(cache.keys())\n",
    "\n",
    "for idx1, bname1 in enumerate(tqdm(inputs)):\n",
    "    current = idx1\n",
    "    if current in visited and predicted_ratings[current]!=0:\n",
    "        print(f'Already visited {current}')\n",
    "        continue\n",
    "\n",
    "    visited.append(current)\n",
    "\n",
    "    key = f'{current}'\n",
    "    if key in cached_keys:\n",
    "        choices = cache[key]['choices']\n",
    "        print('Using cached choices for key', key)\n",
    "    else:\n",
    "        prompt = generate_prompt(current)#(example_idxs, current_pair)\n",
    "        response=False\n",
    "        i=0\n",
    "        while not response:\n",
    "            i+=1\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=engine,\n",
    "                    messages=[{'role':'user', 'content':prompt}],\n",
    "                    temperature=temperature,\n",
    "                    timeout=10\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f'Attempt {i} failed')\n",
    "                time.sleep(5)\n",
    "        choices = [dict(choice.items()) for choice in response.choices]\n",
    "\n",
    "        cache[key] = {\n",
    "            'prompt': prompt,\n",
    "            'choices': choices,\n",
    "            'created': response.created\n",
    "        }\n",
    "\n",
    "        request_count += 1\n",
    "        if cache and request_count % 5 == 0:\n",
    "            json.dump(cache, open(create_cache_filename(), 'w'))\n",
    "\n",
    "    try:\n",
    "        answer = choices[0]['message']['content'].replace('\\n', '').strip()\n",
    "        predicted_ratings[idx1] = int(answer)\n",
    "    except:\n",
    "        print('Error', cache[key])\n",
    "\n",
    "os.makedirs(f'predictions/{stim_set}', exist_ok=True)\n",
    "np.save(f'predictions/{stim_set}/{stim_set}-{n_context}-{engine}-{temperature}-{seed}.npy', predicted_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6414f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/600-words-Atlantic-CSV-Formal-Informal-Fiction-Full.csv\") #read in the OG dataframe again\n",
    "predicted_ratings=np.load(f'predictions/{stim_set}/{stim_set}-{n_context}-{engine}-{temperature}-{seed}.npy', allow_pickle=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc227656",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings # just to check it ran smoothly\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f277f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arousal_df_gpt35_250=pd.DataFrame(predicted_ratings, columns=['gpt_arousal_ratings'])\n",
    "arousal_df_gpt35_250['Text']=df.Text.values #update to whatever the txt column is called\n",
    "arousal_df_gpt35_250['SID']=df.file_name.values #update to SID column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2397e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the work\n",
    "output_directory = '/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/output/final/' #update to where you want to save the work\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "arousal_df_gpt35_250.to_csv(os.path.join(output_directory, f'{stim_set}-{n_context}-{engine}-{temperature}-{seed}.csv'), index=False) #saving the pandas dataframe to a csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a85b19c0",
   "metadata": {},
   "source": [
    "## Emotional Tone (with examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c073fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    # set directory to get .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05ade05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2\n"
     ]
    }
   ],
   "source": [
    "# set directory to get .env file. You will need to change this to wherever your API key (.env file) is, as well as where you want to save your results\n",
    "%cd \"/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68b2efe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file_name</th>\n",
       "      <th>Text</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>gpt_coding_raw</th>\n",
       "      <th>gpt_coding_final</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35071</td>\n",
       "      <td>641130-the-wealth-we-wasted.txt</td>\n",
       "      <td>The Wealth We Wasted The Wealth We Wasted A. W...</td>\n",
       "      <td>1952</td>\n",
       "      <td>8</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>['The', 'Wealth', 'We', 'Wasted', 'The', 'Weal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35072</td>\n",
       "      <td>641803-the-peripatetic-reviewer.txt</td>\n",
       "      <td>The Peripatetic Reviewer The Peripatetic Revie...</td>\n",
       "      <td>1952</td>\n",
       "      <td>8</td>\n",
       "      <td>Non-fiction.</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>['The', 'Peripatetic', 'Reviewer', 'The', 'Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35073</td>\n",
       "      <td>641018-a-life-of-disagreement.txt</td>\n",
       "      <td>A Life of Disagreement A Life of Disagreement ...</td>\n",
       "      <td>1952</td>\n",
       "      <td>8</td>\n",
       "      <td>Non-fiction.</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>['A', 'Life', 'of', 'Disagreement', 'A', 'Life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35075</td>\n",
       "      <td>641902-spain.txt</td>\n",
       "      <td>Spain Spain on the World TodayDURING the riots...</td>\n",
       "      <td>1952</td>\n",
       "      <td>8</td>\n",
       "      <td>Non-fiction.</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>['Spain', 'Spain', 'on', 'the', 'World', 'Toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35076</td>\n",
       "      <td>642759-record-reviews.txt</td>\n",
       "      <td>Record Reviews Record Reviews John M. Conly by...</td>\n",
       "      <td>1952</td>\n",
       "      <td>8</td>\n",
       "      <td>Non-fiction.</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>['Record', 'Reviews', 'Record', 'Reviews', 'Jo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            file_name   \n",
       "0       35071      641130-the-wealth-we-wasted.txt  \\\n",
       "1       35072  641803-the-peripatetic-reviewer.txt   \n",
       "2       35073    641018-a-life-of-disagreement.txt   \n",
       "3       35075                     641902-spain.txt   \n",
       "4       35076            642759-record-reviews.txt   \n",
       "\n",
       "                                                Text  year  month   \n",
       "0  The Wealth We Wasted The Wealth We Wasted A. W...  1952      8  \\\n",
       "1  The Peripatetic Reviewer The Peripatetic Revie...  1952      8   \n",
       "2  A Life of Disagreement A Life of Disagreement ...  1952      8   \n",
       "3  Spain Spain on the World TodayDURING the riots...  1952      8   \n",
       "4  Record Reviews Record Reviews John M. Conly by...  1952      8   \n",
       "\n",
       "  gpt_coding_raw gpt_coding_final   \n",
       "0    non-fiction      non-fiction  \\\n",
       "1   Non-fiction.      non-fiction   \n",
       "2   Non-fiction.      non-fiction   \n",
       "3   Non-fiction.      non-fiction   \n",
       "4   Non-fiction.      non-fiction   \n",
       "\n",
       "                                              Tokens  \n",
       "0  ['The', 'Wealth', 'We', 'Wasted', 'The', 'Weal...  \n",
       "1  ['The', 'Peripatetic', 'Reviewer', 'The', 'Per...  \n",
       "2  ['A', 'Life', 'of', 'Disagreement', 'A', 'Life...  \n",
       "3  ['Spain', 'Spain', 'on', 'the', 'World', 'Toda...  \n",
       "4  ['Record', 'Reviews', 'Record', 'Reviews', 'Jo...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/500-words-Atlantic-CSV-Formal-Informal-Fiction-Full.csv') # load in the data using pandas and take a peek at the first 10 rows\n",
    "df.head(10) #grab the text column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fbe650e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>year</th>\n",
       "      <th>Example</th>\n",
       "      <th>Label</th>\n",
       "      <th>formality_rating</th>\n",
       "      <th>gpt_coding_final</th>\n",
       "      <th>angela_formality_rating</th>\n",
       "      <th>lyle_formality_rating</th>\n",
       "      <th>ben_formality_rating</th>\n",
       "      <th>steven_formality_rating</th>\n",
       "      <th>interrater_reliability</th>\n",
       "      <th>overall_inter_rater_reliability</th>\n",
       "      <th>GPT3_5_NO_example</th>\n",
       "      <th>no_example_cor</th>\n",
       "      <th>GPT3_5_with_example</th>\n",
       "      <th>example_cor</th>\n",
       "      <th>GPT3_5_2_example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628188-the-question-of-the-hour.txt</td>\n",
       "      <td>1861</td>\n",
       "      <td>However true this may be in the main, — and it...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280369</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633747-why-our-science-students-go-to-germany.txt</td>\n",
       "      <td>1889</td>\n",
       "      <td>Doubtless each individual is influenced by a v...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280369</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>659289-why-im-a-cop-interviews-from-a-reporter...</td>\n",
       "      <td>1969</td>\n",
       "      <td>New York policeman for ten years; recently bec...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280369</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>307617-how-american-health-care-killed-my-fath...</td>\n",
       "      <td>2009</td>\n",
       "      <td>Like every grieving family member, I looked fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.222222</td>\n",
       "      <td>0.280369</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  year   \n",
       "0                628188-the-question-of-the-hour.txt  1861  \\\n",
       "1  633747-why-our-science-students-go-to-germany.txt  1889   \n",
       "2  659289-why-im-a-cop-interviews-from-a-reporter...  1969   \n",
       "3  307617-how-american-health-care-killed-my-fath...  2009   \n",
       "\n",
       "                                             Example  Label  formality_rating   \n",
       "0  However true this may be in the main, — and it...      1               NaN  \\\n",
       "1  Doubtless each individual is influenced by a v...      1               NaN   \n",
       "2  New York policeman for ten years; recently bec...      0               NaN   \n",
       "3  Like every grieving family member, I looked fo...      0               NaN   \n",
       "\n",
       "  gpt_coding_final  angela_formality_rating  lyle_formality_rating   \n",
       "0      non-fiction                        1                      1  \\\n",
       "1      non-fiction                        1                      1   \n",
       "2      non-fiction                        0                      0   \n",
       "3      non-fiction                        1                      0   \n",
       "\n",
       "   ben_formality_rating  steven_formality_rating  interrater_reliability   \n",
       "0                     1                        1                1.000000  \\\n",
       "1                     1                        1                1.000000   \n",
       "2                     0                        0                1.000000   \n",
       "3                     0                        0               -0.222222   \n",
       "\n",
       "   overall_inter_rater_reliability  GPT3_5_NO_example  no_example_cor   \n",
       "0                         0.280369                  1             NaN  \\\n",
       "1                         0.280369                  1             NaN   \n",
       "2                         0.280369                  0             NaN   \n",
       "3                         0.280369                  0             NaN   \n",
       "\n",
       "   GPT3_5_with_example  example_cor  GPT3_5_2_example  \n",
       "0                    1          NaN                 1  \n",
       "1                    1          NaN                 1  \n",
       "2                    0          NaN                 0  \n",
       "3                    0          NaN                 0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tone examples \n",
    "examples=pd.read_csv('/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/GPT-examples/Atlantic-Nonfiction-Examples.csv') #update with the relevant CSV path\n",
    "examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e2d5493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The Wealth We Wasted The Wealth We Wasted A. W. Smith A. W. SMITH , who was born in Spain of British parents , lived in Russia as a boy and was educated at Shrewsbury and at Sandhurst . He served with the British Army throughout both World Wars . For some years he has made his home in Ipswich , Massachusetts , where he wrote his books , The Captain Departed and The Sword and the Rose , and a number of short stories which have appeared in the Atlantic . He has recently become an American citizen , and is today a Vice President on the staff of The Conservation Foundation . by A. W. SMITH1IT is probably near-heresy to suggest that the pioneer forefathers may not have been well equipped to deal intelligently with the problems posed in their new environment . Many of their practices , so evil and so wasteful in the coldly superior light of the middle of the twentieth century , may have been forced on them by the demands of the moment . But these are not sufficient to account for the destructive waste which has been the habit of American pioneers up to our own times.The early settlers — and the majority of later ones , too — were English . They came to a land which differed but little from England in climate and soil types . It had much the same pattern of precipitation . Winter might be a bit colder , summer rather hotter , but the same crops could be grown with much the same techniques . Yet the first settlers and their successors failed to bring with them any significant part of the great available knowledge of land use . They seem to have abandoned past experience almost before they started , together with any feel for land or sympathy for its needs.These people came from a land of highly developed resource use , where the countryside was loved and appreciated for itself . It was the England of Tom Tusser , the farmer poet , who coined such pleasant and even truthful aphorisms as `` March dust worth a ransom of gold '' ; `` Sweet April showers spring May flowers '' ; `` Calm in June sets corn in tune . '' It was the England of Evelyn , of Izaak Walton and Cotton . And of the anonymous author who improved on Bernard of Cluny 's Jerusalem the Golden with a lovelier and longer version which includes what is clearly a trout stream among the important delights of the life to come.Whether they came from motives of freedom or fortune , the early settlers seem to have been taken completely by surprise by what they found in America . The Jamestown Settlement , consisting of forty-eight gentlemen and four carpenters , were told quite plainly at the outset that they would be `` banished men '' unless they produced cargoes to the value\"\n",
      " \"The Peripatetic Reviewer The Peripatetic Reviewer Edward Weeks BECAUSE I find fishing , the play of sunlight and shadow on water and the signals of the life beneath , the most complete and bewitching relaxation from a life devoted to print , I am occasionally asked for advice , not as an expert but as an addict who has learned from his trials . `` Jack has always had a yen to fish , '' said the wife of a friend recently , `` but now that he 's got the time , he 's too shy to begin . Claims he does n't know anything about casting or what tackle to get . How do I push him in ? '' I think that 's true of more fifty-year-olds than ever admit it : their friends who belong to the fraternity of the dry fly talk a jargon that will scare away most beginners . What Jack needs for his conversion is the joy of catching fish ; the art of not catching he can develop later . Specifically what he needs is an old hat , a pair of sneakers , and a bottle of insect repellent . I did my learning on a Bristol split-bamboo rod that cost $ 16 ; Jack can do his on a mediumpriced fly rod and reel at a cost of $ 30 , or as much more as he cares to pay ( the famous name-rods , a Leonard , a Thomas , a Paine , or a Hardy , will come close to $ 100 ) . But most of all , Jack needs the tight line and the feel of a jumping smallmouthed or the swift rush of a trout . He should not be ashamed to use bait . I know two friends who fish a mountain brook . The brook has two branches winding through three miles of thick brush . They leave one car at the bottom , drive to the top , and go their separate ways with worm cans . They never fail to catch enough brookies for the meal when they converge — and incidentally , the bottom pool is an excellent icebox for their bottled beer . So what Jack needs is worms for the trout brook , or minnows or hellgrammites for the bass pond . Plenty of time for the dry flies after his conversion . A second friend , setting off in early July for a month 's cruise which will carry him as far as Newfoundland , asked if I thought he could hold a salmon on his telescopic steel rod . I said I thought he could , and gave him the names of the three standard wet flies ( size 4 ) which a salmon might rise to at the river 's mouth —Black Dose , Durham Ranger , and Mar Lodge . That collapsible steel rod of his is probably the best all-purpose implement for\"\n",
      " \"A Life of Disagreement A Life of Disagreement Romney Wheeler Of all the television programs in recent months , few attracted such widespread praise as the half-hour conversation by BERTRAND RUSSELL with Romney Wheeler , filmed in London by the National Broadcasting Company and shown over the NBC network and BBC-TV on the occasion of Earl Russell 's eightieth birthday . Author , philosopher , mathematician , and recipient of the Nobel Prize in Literature , Earl Russell believes that mankind will yet `` emerge into some world that will be happier than any world that has existed in the past . '' We feel sure Atlantic readers trill enjoy this complete transcript of the interview . An Interview with Bertrand RussellWHEELER . — Lord Russell , as you celebrate your eightieth birthday , we 'd like you to tell us what you think you have learned and what you think you will never learn in your career as a philosopher.RUSSELL . — Well , there are some things that I do n't think I shall ever learn and indeed I hope I shall never learn . I do n't wish to learn to change my hopes for the world . I am prepared to change my beliefs about the state of the world , but not my hopes . About that I wish to remain constant . I think we might call the subject of our talk `` Eighty years of changing beliefs and unchanging hopes . `` It 's very difficult for anybody born since 1914 to realize how profoundly different the world is now from what it was when I was a child . The change has been almost unbelievable . I try as best I can , despite my years , to get used to living in a world of atom bombs ; a world where ancient empires vanish like morning mist , where we have to accustom ourselves to Asiatic self-assertion , the Communist menace . The world is altogether different from what it was when I was young . It 's an extraordinarily difficult thing for an old man to live in such a world . I was born in 1872 . My parents died when I was still an infant . And so I was brought up by my grandparents.WHEELER . — Can you tell us something about your grandfather ? RUSSELL . — Yes . He was born in the early years of the French Revolution . He was a member of Parliament while Napoleon was on the throne . In common with Fox , he thought English hostility to Napoleon was excessive , and he visited Napoleon in Elba . It was he who introduced the reform in 1832 which started England on the road towards democracy . He was Prime Minister during the Mexican War , during the Revolutions of 1848 . I remember him quite well . But as you can see , he belonged to an age that\"]\n"
     ]
    }
   ],
   "source": [
    "inputs = df.Text.values #save the text\n",
    "print(inputs[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b35e7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load other dependencies \n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b414459",
   "metadata": {},
   "outputs": [],
   "source": [
    "title='BBPRIME'\n",
    "subtitle='Arousal'\n",
    "stim_set=title+'-'+subtitle\n",
    "seed=1 #set seed to make sure we get reproducable results \n",
    "temperature=0.0 #want a low baking temp to have little variability or creativity, and so we can get the same results every. single. time. range is 0-1\n",
    "engine='gpt-3.5-turbo' #change this to use different models available to you via OpenAI\n",
    "n_context=1\n",
    "cache = True   \n",
    "resume=False\n",
    "# MIDI='freq' #or 'name', 'number', 'freq'\n",
    "audience='People'\n",
    "item='Text'\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "apiKey = os.environ.get('steven_key') #for stevens key. update to you whatever you're calling your api_key. it should look like this in your file\n",
    "\n",
    "# apiKey = sk-ZJ...................4T\n",
    "\n",
    "openai.api_key = apiKey #installize the key so we can access\n",
    "\n",
    "if cache:\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239a74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(current):#(example_idxs, current_pair):\n",
    "    prompt = f\"\"\"Your task is to classify the emptional tone of a piece of text positive or negative. Emotional tone is the degree of positivity or negativity of a text. Positive tone has a more upbeat\n",
    "style and can include words like “good, well, new, love” but is not limited to these words. Negative tone reveals anxiety, sadness, and hostility and can include words like “bad, wrong, hate, too much” but is not limited to these words.\n",
    "You will be provided with XX examples of text with a positive tone and XX examples of text with a negative tone. Answer with only a number, with 0 being negative tone and 1 being positive tone\n",
    "\n",
    "Text: {examples.Example.iloc[0]} \n",
    "Rating: {examples.Label.iloc[0]}\n",
    "    \n",
    "Text: {examples.Example.iloc[1]}\n",
    "Rating: {examples.Label.iloc[1]}\n",
    "\n",
    "Text: {examples.Example.iloc[2]}\n",
    "Rating: {examples.Label.iloc[2]}\n",
    "\n",
    "Text: {examples.Example.iloc[3]}\n",
    "Rating: {examples.Label.iloc[3]}\n",
    "    \n",
    "Text: {inputs[current]}\n",
    "Rating:\n",
    "\"\"\"\n",
    "    if n_context==0:\n",
    "        prompt = f\"\"\"Does this text have a positive or negative tone? Answer with only a number, with 0 being negative tone and 1 being positive tone. Here is the text:\\n{inputs[current]}\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "cache_folder = f'cache/{stim_set}'\n",
    "os.makedirs(cache_folder, exist_ok=True)\n",
    "\n",
    "def create_cache_filename():\n",
    "    filename = f'{stim_set}-{n_context}-{engine}-{temperature}-{seed}'\n",
    "    # if args.shuffle_context_each_draw:\n",
    "    #     filename += '-shuffle'\n",
    "    return os.path.join(cache_folder, filename + '.json')\n",
    "\n",
    "if not resume:\n",
    "    visited = []\n",
    "    predicted_ratings = np.zeros((len(inputs)))\n",
    "    request_count = 0\n",
    "\n",
    "cache = {}\n",
    "\n",
    "if cache and os.path.exists(create_cache_filename()):\n",
    "    cache = json.load(open(create_cache_filename()))\n",
    "cached_keys = list(cache.keys())\n",
    "\n",
    "for idx1, bname1 in enumerate(tqdm(inputs)):\n",
    "    current = idx1\n",
    "    if current in visited and predicted_ratings[current] != 0:\n",
    "        print(f'Already visited {current}')\n",
    "        continue\n",
    "\n",
    "    visited.append(current)\n",
    "\n",
    "    key = f'{current}'\n",
    "    if key in cached_keys:\n",
    "        choices = cache[key]['choices']\n",
    "        print('Using cached choices for key', key)\n",
    "    else:\n",
    "        prompt = generate_prompt(current)\n",
    "        response = False\n",
    "        i = 0\n",
    "        while not response:\n",
    "            i += 1\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=engine,\n",
    "                    messages=[{'role': 'user', 'content': prompt}],\n",
    "                    temperature=temperature,\n",
    "                    timeout=10\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f'Attempt {i} failed\\n{e}\\n')\n",
    "                \n",
    "                time.sleep(7) #7 second delay \n",
    "        choices = [dict(choice.items()) for choice in response.choices]\n",
    "\n",
    "        cache[key] = {\n",
    "            'prompt': prompt,\n",
    "            'choices': choices,\n",
    "            'created': response.created\n",
    "        }\n",
    "\n",
    "        request_count += 1\n",
    "        if cache and request_count % 5 == 0:\n",
    "            json.dump(cache, open(create_cache_filename(), 'w'))\n",
    "\n",
    "    try:\n",
    "        answer = choices[0]['message']['content'].replace('\\n', '').strip()\n",
    "        predicted_ratings[idx1] = int(answer)\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}\\n\\n{cache[key]}')\n",
    "\n",
    "os.makedirs(f'predictions/{stim_set}', exist_ok=True)\n",
    "np.save(f'predictions/{stim_set}/{stim_set}-{n_context}-{engine}-{temperature}-{seed}.npy', predicted_ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d581d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/Users/stevenmesquiti/Dropbox/Collected Texts/Atlantic-csv/600-words-Atlantic-CSV-Formal-Informal-Fiction-Full.csv\") #read in the OG dataframe again\n",
    "predicted_ratings=np.load(f'predictions/{stim_set}/{stim_set}-{n_context}-{engine}-{temperature}-{seed}.npy', allow_pickle=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85be58ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'file_name', 'Text', 'year', 'month', 'gpt_coding_raw',\n",
       "       'gpt_coding_final', 'Tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings # just to check it ran smoothly\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35cf6fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_df_gpt35=pd.DataFrame(predicted_ratings, columns=['tone_ratings'])\n",
    "tone_df_gpt35['Text']=df.Text.values #update with text column \n",
    "tone_df_gpt35['SID']=df.file_name.values #update with indexing variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5207df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the work\n",
    "output_directory = '/Users/stevenmesquiti/Desktop/working-with-lyle/Text-Annotation/blind-round-2/output/final' #update to your own directory \n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "tone_df_gpt35.to_csv(os.path.join(output_directory, f'{stim_set}-{n_context}-{engine}-{temperature}-{seed}.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
